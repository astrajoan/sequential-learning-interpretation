# sequential learning interpretation
Deep learning, and in particular, recurrent neural networks, has in recent years gained nonstop interest with its successful application in a broad range of areas. These include handwriting recognition, natural language processing, speed recognition and so on. However, with the ever expanding use of such models, their interpretability or the mechanism of their decision making process have been understudied. Such interpretation can not only help users trust the models and predictions more, but also provide valuable insights into various areas, such as genetic modeling and linguistics, and help with model designs.

Here, we organized papers and articles from difference sources to provide a somewhat full-around overview of the development in this area.

## directions in sequential learning interpretation


## to start with
### papers
- [Visualizing and understanding recurrent networks (Andrej Karpathy, Justin Johnson, Li Fei-Fei)](https://arxiv.org/pdf/1506.02078.pdf?ref=https://codemonkey.link)(Andrej Karpathy, Justin Johnson, Li Fei-Fei)
- [Techniques for Interpretable Machine Learning (Mengnan Du, Ninghao Liu, Xia Hu)](https://arxiv.org/pdf/1808.00033.pdf)


### articles
- [Interpreting recurrent neural networks on multivariate time series](https://towardsdatascience.com/interpreting-recurrent-neural-networks-on-multivariate-time-series-ebec0edb8f5a)


## interpretation principle
- [based on model](#based-on-model)
- [based on data](#based-on-data)
- [based on interpretation methods](#based-on-interpretation-methods)



### based on model
#### LSTM
- [Visualizing and understanding recurrent networks (Andrej Karpathy, Justin Johnson, Li Fei-Fei)](https://arxiv.org/pdf/1506.02078.pdf?ref=https://codemonkey.link)


### based on data
#### medical data
- [Interpretability of time-series deep learning models: A study in cardiovascular patients admitted to Intensive care unit (Ilaria Gandin, Arjuna Scagnetto, Simona Romani, Giulia Barbati)](https://www.sciencedirect.com/science/article/pii/S1532046421002057)


### based on interpretation methods
- [On Attribution of Recurrent Neural Network Predictions via Additive Decomposition (Mengnan Du, Ninghao Liu, Fan Yang, Shuiwang Ji, Xia Hu)](https://arxiv.org/pdf/1903.11245.pdf)
- [Interpretation of Prediction Models Using the Input Gradient (Yotam Hechtlinger)](https://arxiv.org/pdf/1611.07634.pdf?ref=https://githubhelp.com)



