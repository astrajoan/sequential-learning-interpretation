# sequential learning interpretation
Deep learning, and in particular, recurrent neural networks, has in recent years gained nonstop interest with its successful application in a broad range of areas. These include handwriting recognition, natural language processing, speed recognition and so on. However, with the ever expanding use of such models, their interpretability or the mechanism of their decision making process have been understudied. Such interpretation can not only help users trust the models and predictions more, but also provide valuable insights into various areas, such as genetic modeling and linguistics, and help with model designs.

Here, we organized papers and articles from difference sources to provide a somewhat full-around overview of the development in this area.

## directions in sequential learning interpretation
### definition
- [Towards A Rigorous Science of Interpretable Machine Learning](https://arxiv.org/pdf/1702.08608.pdf) (Finale Doshi-Velez, Been Kim; 2017)

## to start with
### papers
- [“Why Should I Trust You?” Explaining the Predictions of Any Classifier](https://arxiv.org/pdf/1602.04938.pdf?ref=morioh.com) (Marco Tulio Ribeiro, Sameer Singh, Carlos Guestrin)
- [A Unified Approach to Interpreting Model Predictions](https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf) (Scott M. Lundberg, Su-In Lee)
- [Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation](https://arxiv.org/pdf/1406.1078.pdf?ref=https://codemonkey.link) (Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio)
- [Visualizing and understanding recurrent networks](https://arxiv.org/pdf/1506.02078.pdf?ref=https://codemonkey.link) (Andrej Karpathy, Justin Johnson, Li Fei-Fei)
- [Techniques for Interpretable Machine Learning](https://arxiv.org/pdf/1808.00033.pdf) (Mengnan Du, Ninghao Liu, Xia Hu)
- [On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation](https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0130140&type=printable&ref=https://githubhelp.com) (Sebastian Bach, Alexander Binder, Grégoire Montavon, Frederick Klauschen, Klaus-Robert Müller, Wojciech Samek)


### articles
- [Interpreting recurrent neural networks on multivariate time series](https://towardsdatascience.com/interpreting-recurrent-neural-networks-on-multivariate-time-series-ebec0edb8f5a)


## based on interpretation methods
### SHAP
- [Interpreting a Recurrent Neural Network’s Predictions of ICU Mortality Risk](https://arxiv.org/pdf/1905.09865.pdf) (Long V. Hoa, Melissa Aczona, David Ledbettera, Randall Wetzela)



### composition
- [On Attribution of Recurrent Neural Network Predictions via Additive Decomposition](https://arxiv.org/pdf/1903.11245.pdf) (Mengnan Du, Ninghao Liu, Fan Yang, Shuiwang Ji, Xia Hu)
- [Visualizing and Understanding Neural Models in NLP](https://arxiv.org/pdf/1506.01066.pdf) (Jiwei Li, Xinlei Chen, Eduard Hovy and Dan Jurafsky)


### gradient
- [Interpretation of Prediction Models Using the Input Gradient](https://arxiv.org/pdf/1611.07634.pdf?ref=https://githubhelp.com) (Yotam Hechtlinger)


### sparse constraint


### backpropagation
- [Explaining Recurrent Neural Network Predictions in Sentiment Analysis](https://arxiv.org/pdf/1706.07206.pdf) (Leila Arras, Gregoire Montavon, Klaus-Robert Muller, Wojciech Samek)


### attention
- [Interpretability of time-series deep learning models: A study in cardiovascular patients admitted to Intensive care unit](https://www.sciencedirect.com/science/article/pii/S1532046421002057) (Ilaria Gandin, Arjuna Scagnetto, Simona Romani, Giulia Barbati)

